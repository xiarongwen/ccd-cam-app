//
//  CameraService.swift
//  ccd
//
//  Created by IT on 2025/5/23.
//

import AVFoundation
import SwiftUI
import CoreImage
import Photos

class CameraService: NSObject, ObservableObject {
    // MARK: - Published Properties
    @Published var session = AVCaptureSession()
    @Published var isSessionRunning = false
    @Published var isAuthorized = false
    @Published var flashMode: AVCaptureDevice.FlashMode = .off
    @Published var currentZoomFactor: CGFloat = 1.0
    @Published var isCapturing = false
    @Published var previewImage: CIImage?
    @Published var currentFilter: FilterType = .none
    @Published var isUsingFrontCamera: Bool = false
    @Published var deviceOrientation: UIDeviceOrientation = .portrait
    @Published var currentLens: CameraLensType = .wide
    
    // MARK: - Session Management
    private let sessionQueue = DispatchQueue(label: "camera.session.queue")
    private let videoDataQueue = DispatchQueue(label: "camera.video.queue")
    private var videoDeviceInput: AVCaptureDeviceInput?
    let photoOutput = AVCapturePhotoOutput()
    private let videoDataOutput = AVCaptureVideoDataOutput()
    private var videoDevice: AVCaptureDevice?
    
    // MARK: - Photo Capture
    private var inFlightPhotoCaptureProcessors: [Int64: PhotoCaptureProcessor] = [:]
    
    // MARK: - Filter Processing
    private let context = CIContext()
    private var lastProcessTime: CFTimeInterval = 0
    private let processInterval: CFTimeInterval = 1.0/15.0 // 15 FPS
    
    // MARK: - Initialization
    override init() {
        super.init()
        setupOrientationMonitoring()
        checkPermissions()
    }
    
    // MARK: - Permission Handling
    func checkPermissions() {
        switch AVCaptureDevice.authorizationStatus(for: .video) {
        case .authorized:
            isAuthorized = true
            setupSession()
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { [weak self] granted in
                DispatchQueue.main.async {
                    self?.isAuthorized = granted
                    if granted {
                        self?.setupSession()
                    }
                }
            }
        default:
            isAuthorized = false
        }
    }
    
    // MARK: - Session Configuration
    func setupSession() {
        sessionQueue.async { [weak self] in
            self?.configureSession()
        }
    }
    
    private func configureSession() {
        print("ğŸ”§ å¼€å§‹é…ç½®ç›¸æœºä¼šè¯...")
        session.beginConfiguration()
        session.sessionPreset = .photo
        print("ğŸ”§ è®¾ç½®ä¼šè¯é¢„è®¾ä¸º .photo")
        
        // Add video input
        do {
            var defaultVideoDevice: AVCaptureDevice?
            
            if let dualCameraDevice = AVCaptureDevice.default(.builtInDualCamera, for: .video, position: .back) {
                defaultVideoDevice = dualCameraDevice
                print("ğŸ”§ ä½¿ç”¨åŒæ‘„åƒå¤´")
                isUsingFrontCamera = false
            } else if let backCameraDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) {
                defaultVideoDevice = backCameraDevice
                print("ğŸ”§ ä½¿ç”¨åç½®å¹¿è§’æ‘„åƒå¤´")
                isUsingFrontCamera = false
            }
            
            guard let videoDevice = defaultVideoDevice else {
                print("ğŸ”§ é”™è¯¯ï¼šæ— æ³•è·å–é»˜è®¤è§†é¢‘è®¾å¤‡")
                session.commitConfiguration()
                return
            }
            
            let videoDeviceInput = try AVCaptureDeviceInput(device: videoDevice)
            
            if session.canAddInput(videoDeviceInput) {
                session.addInput(videoDeviceInput)
                self.videoDeviceInput = videoDeviceInput
                self.videoDevice = videoDevice
                print("ğŸ”§ æˆåŠŸæ·»åŠ è§†é¢‘è¾“å…¥")
            } else {
                print("ğŸ”§ é”™è¯¯ï¼šæ— æ³•æ·»åŠ è§†é¢‘è¾“å…¥åˆ°ä¼šè¯")
                session.commitConfiguration()
                return
            }
        } catch {
            print("ğŸ”§ é”™è¯¯ï¼šåˆ›å»ºè§†é¢‘è¾“å…¥å¤±è´¥: \(error)")
            session.commitConfiguration()
            return
        }
        
        // Add photo output
        print("ğŸ”§ å°è¯•æ·»åŠ ç…§ç‰‡è¾“å‡º...")

        if session.canAddOutput(photoOutput) {
            session.addOutput(photoOutput)
            photoOutput.isHighResolutionCaptureEnabled = true
            photoOutput.maxPhotoQualityPrioritization = .quality
            print("ğŸ”§ æˆåŠŸæ·»åŠ ç…§ç‰‡è¾“å‡º")
            print("ğŸ”§ photoOutput.isHighResolutionCaptureEnabled: \(photoOutput.isHighResolutionCaptureEnabled)")
            print("ğŸ”§ photoOutput.maxPhotoQualityPrioritization: \(photoOutput.maxPhotoQualityPrioritization.rawValue)")
        } else {
            print("ğŸ”§ é”™è¯¯ï¼šæ— æ³•æ·»åŠ ç…§ç‰‡è¾“å‡ºåˆ°ä¼šè¯")
            session.commitConfiguration()
            return
        }
        
        // Add video data output for real-time processing
        print("ğŸ”§ å°è¯•æ·»åŠ è§†é¢‘æ•°æ®è¾“å‡º...")
        if session.canAddOutput(videoDataOutput) {
            session.addOutput(videoDataOutput)
            videoDataOutput.setSampleBufferDelegate(self, queue: videoDataQueue)
            videoDataOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA]
            
            if let connection = videoDataOutput.connection(with: .video) {
                connection.isEnabled = true
                
                // è®¾ç½®åˆå§‹è§†é¢‘æ–¹å‘
                if connection.isVideoOrientationSupported {
                    let videoOrientation = convertDeviceOrientationToVideoOrientation(deviceOrientation)
                    connection.videoOrientation = videoOrientation
                    print("ğŸ”§ è®¾ç½®è§†é¢‘è¾“å‡ºæ–¹å‘ä¸º: \(videoOrientation.rawValue)")
                }
                
                // è®¾ç½®è§†é¢‘ç¨³å®šæ¨¡å¼
                if connection.isVideoStabilizationSupported {
                    connection.preferredVideoStabilizationMode = .auto
                }
                
                print("ğŸ”§ æˆåŠŸé…ç½®è§†é¢‘æ•°æ®è¾“å‡ºè¿æ¥")
            }
            print("ğŸ”§ æˆåŠŸæ·»åŠ è§†é¢‘æ•°æ®è¾“å‡º")
        } else {
            print("ğŸ”§ è­¦å‘Šï¼šæ— æ³•æ·»åŠ è§†é¢‘æ•°æ®è¾“å‡º")
        }
        
        session.commitConfiguration()
        print("ğŸ”§ ä¼šè¯é…ç½®å®Œæˆ")
        print("ğŸ”§ ä¼šè¯è¾“å…¥æ•°é‡: \(session.inputs.count)")
        print("ğŸ”§ ä¼šè¯è¾“å‡ºæ•°é‡: \(session.outputs.count)")
    }
    
    // MARK: - Session Control
    func startSession() {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            if !self.session.isRunning {
                self.session.startRunning()
                DispatchQueue.main.async {
                    self.isSessionRunning = true
                }
            }
        }
    }
    
    func stopSession() {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            if self.session.isRunning {
                self.session.stopRunning()
                DispatchQueue.main.async {
                    self.isSessionRunning = false
                }
            }
        }
    }
    
    // MARK: - Filter Control
    func updateFilter(_ filter: FilterType) {
        currentFilter = filter
    }
    
    // MARK: - Camera Control
    func switchCamera() {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            
            guard let currentVideoDevice = self.videoDeviceInput?.device else { return }
            let currentPosition = currentVideoDevice.position
            let preferredPosition: AVCaptureDevice.Position = currentPosition == .back ? .front : .back
            
            let devices = AVCaptureDevice.DiscoverySession(
                deviceTypes: [.builtInWideAngleCamera, .builtInDualCamera, .builtInTrueDepthCamera],
                mediaType: .video,
                position: .unspecified
            ).devices
            
            guard let newVideoDevice = devices.first(where: { $0.position == preferredPosition }) else { return }
            
            do {
                let newVideoDeviceInput = try AVCaptureDeviceInput(device: newVideoDevice)
                
                self.session.beginConfiguration()
                
                if let currentInput = self.videoDeviceInput {
                    self.session.removeInput(currentInput)
                }
                
                if self.session.canAddInput(newVideoDeviceInput) {
                    self.session.addInput(newVideoDeviceInput)
                    self.videoDeviceInput = newVideoDeviceInput
                    self.videoDevice = newVideoDevice
                    
                    // æ›´æ–°å‰ç½®/åç½®ç›¸æœºçŠ¶æ€
                    DispatchQueue.main.async {
                        self.isUsingFrontCamera = (newVideoDevice.position == .front)
                    }
                }
                
                self.session.commitConfiguration()
            } catch {
                print("Error switching cameras: \(error)")
            }
        }
    }
    
    // MARK: - Focus & Exposure
    func focus(at point: CGPoint) {
        guard let device = videoDevice else { return }
        
        do {
            try device.lockForConfiguration()
            
            if device.isFocusPointOfInterestSupported && device.isFocusModeSupported(.autoFocus) {
                device.focusPointOfInterest = point
                device.focusMode = .autoFocus
            }
            
            if device.isExposurePointOfInterestSupported && device.isExposureModeSupported(.autoExpose) {
                device.exposurePointOfInterest = point
                device.exposureMode = .autoExpose
            }
            
            device.unlockForConfiguration()
        } catch {
            print("Could not lock device for configuration: \(error)")
        }
    }
    
    // MARK: - Zoom
    func zoom(factor: CGFloat) {
        guard let device = videoDevice else { return }
        
        do {
            try device.lockForConfiguration()
            device.videoZoomFactor = max(1.0, min(factor, device.activeFormat.videoMaxZoomFactor))
            device.unlockForConfiguration()
            currentZoomFactor = device.videoZoomFactor
        } catch {
            print("Could not lock device for zoom: \(error)")
        }
    }
    
    // MARK: - Flash
    func toggleFlash() {
        switch flashMode {
        case .off:
            flashMode = .on
        case .on:
            flashMode = .auto
        case .auto:
            flashMode = .off
        @unknown default:
            flashMode = .off
        }
    }
    
    // MARK: - Photo Capture
    func capturePhoto(completion: @escaping (Result<UIImage, Error>) -> Void) {
        print("ğŸ”µ CameraService.capturePhoto å¼€å§‹")
        
        guard !isCapturing else {
            print("ğŸ”µ é”™è¯¯ï¼šæ­£åœ¨æ‹ç…§ä¸­")
            return
        }
        
        print("ğŸ”µ æ£€æŸ¥ photoOutput çŠ¶æ€...")
        print("ğŸ”µ photoOutput.connections.count: \(photoOutput.connections.count)")
        print("ğŸ”µ session.outputs.count: \(session.outputs.count)")
        print("ğŸ”µ session.isRunning: \(session.isRunning)")
        
        isCapturing = true
        print("ğŸ”µ è®¾ç½® isCapturing = true")
        
        sessionQueue.async { [weak self] in
            guard let self = self else { 
                print("ğŸ”µ é”™è¯¯ï¼šself ä¸º nil")
                return 
            }
            
            print("ğŸ”µ åœ¨ sessionQueue ä¸­æ‰§è¡Œ...")
            
            let photoSettings = AVCapturePhotoSettings()
            
            // æ£€æŸ¥è®¾å¤‡å…¼å®¹æ€§
            if self.photoOutput.isHighResolutionCaptureEnabled {
                photoSettings.isHighResolutionPhotoEnabled = true
                print("ğŸ”µ å¯ç”¨é«˜åˆ†è¾¨ç‡æ‹ç…§")
            } else {
                print("ğŸ”µ è®¾å¤‡ä¸æ”¯æŒé«˜åˆ†è¾¨ç‡æ‹ç…§")
            }
            
            // æ£€æŸ¥é—ªå…‰ç¯æ”¯æŒ
            if self.photoOutput.supportedFlashModes.contains(self.flashMode) {
                photoSettings.flashMode = self.flashMode
                print("ğŸ”µ è®¾ç½®é—ªå…‰ç¯æ¨¡å¼: \(self.flashMode)")
            } else {
                photoSettings.flashMode = .off
                print("ğŸ”µ è®¾å¤‡ä¸æ”¯æŒå½“å‰é—ªå…‰ç¯æ¨¡å¼ï¼Œè®¾ä¸ºå…³é—­")
            }
            
            print("ğŸ”µ åˆ›å»º photoSettings å®Œæˆ")
            print("ğŸ”µ photoSettings.uniqueID: \(photoSettings.uniqueID)")
            print("ğŸ”µ photoOutput.supportedFlashModes: \(self.photoOutput.supportedFlashModes)")
            print("ğŸ”µ photoOutput.availablePhotoCodecTypes: \(self.photoOutput.availablePhotoCodecTypes)")
            
            if let photoOutputConnection = self.photoOutput.connection(with: .video) {
                // æ ¹æ®å½“å‰è®¾å¤‡æ–¹å‘è®¾ç½®è§†é¢‘æ–¹å‘
                let videoOrientation = self.convertDeviceOrientationToVideoOrientation(self.deviceOrientation)
                photoOutputConnection.videoOrientation = videoOrientation
                print("ğŸ”µ è®¾ç½®ç…§ç‰‡è¾“å‡ºè§†é¢‘æ–¹å‘ä¸º: \(videoOrientation.rawValue), è®¾å¤‡æ–¹å‘: \(self.deviceOrientation.rawValue)")
                
                // ç¡®ä¿ä¸ç¿»è½¬å‰ç½®æ‘„åƒå¤´å›¾åƒ
                photoOutputConnection.isVideoMirrored = self.videoDeviceInput?.device.position == .front
                print("ğŸ”µ é•œåƒè®¾ç½®: \(photoOutputConnection.isVideoMirrored)")
            } else {
                print("ğŸ”µ è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ° video è¿æ¥")
            }
            
            print("ğŸ”µ åˆ›å»º PhotoCaptureProcessor...")
            let photoCaptureProcessor = PhotoCaptureProcessor(
                uniqueID: photoSettings.uniqueID,
                currentFilter: self.currentFilter,
                completion: { [weak self] result in
                    print("ğŸ”µ PhotoCaptureProcessor å›è°ƒè¢«è°ƒç”¨")
                    DispatchQueue.main.async {
                        print("ğŸ”µ åœ¨ä¸»çº¿ç¨‹ä¸­å¤„ç†ç»“æœ...")
                        self?.isCapturing = false
                        
                        // ä»å­—å…¸ä¸­ç§»é™¤å·²å®Œæˆçš„processor
                        self?.inFlightPhotoCaptureProcessors.removeValue(forKey: photoSettings.uniqueID)
                        print("ğŸ”µ å·²æ¸…ç† PhotoCaptureProcessorï¼Œå‰©ä½™æ•°é‡: \(self?.inFlightPhotoCaptureProcessors.count ?? 0)")
                        
                        completion(result)
                    }
                }
            )
            
            // å°†processoræ·»åŠ åˆ°å­—å…¸ä¸­ä»¥æŒæœ‰å¼•ç”¨
            self.inFlightPhotoCaptureProcessors[photoSettings.uniqueID] = photoCaptureProcessor
            print("ğŸ”µ å·²ä¿å­˜ PhotoCaptureProcessor åˆ°å­—å…¸ï¼Œå½“å‰æ•°é‡: \(self.inFlightPhotoCaptureProcessors.count)")
            
            print("ğŸ”µ è°ƒç”¨ photoOutput.capturePhoto...")
            self.photoOutput.capturePhoto(with: photoSettings, delegate: photoCaptureProcessor)
            print("ğŸ”µ photoOutput.capturePhoto è°ƒç”¨å®Œæˆ")
        }
    }
    
    // è®¾ç½®è®¾å¤‡æ–¹å‘ç›‘å¬
    private func setupOrientationMonitoring() {
        // å¼€å§‹ç›‘è§†è®¾å¤‡æ–¹å‘å˜åŒ–
        UIDevice.current.beginGeneratingDeviceOrientationNotifications()
        
        // æ·»åŠ è®¾å¤‡æ–¹å‘å˜åŒ–é€šçŸ¥è§‚å¯Ÿè€…
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(deviceOrientationDidChange),
            name: UIDevice.orientationDidChangeNotification,
            object: nil
        )
        
        // åˆå§‹åŒ–æ–¹å‘
        deviceOrientation = UIDevice.current.orientation
        if !deviceOrientation.isValidInterfaceOrientation {
            deviceOrientation = .portrait
        }
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
        UIDevice.current.endGeneratingDeviceOrientationNotifications()
    }
    
    @objc private func deviceOrientationDidChange() {
        let newOrientation = UIDevice.current.orientation
        
        // åªå¤„ç†æœ‰æ•ˆçš„ç•Œé¢æ–¹å‘
        if newOrientation.isValidInterfaceOrientation {
            DispatchQueue.main.async {
                self.deviceOrientation = newOrientation
            }
            
            // æ›´æ–°è§†é¢‘è¿æ¥çš„æ–¹å‘
            updateVideoConnectionOrientation()
        }
    }
    
    // æ›´æ–°è§†é¢‘è¿æ¥çš„æ–¹å‘è®¾ç½®
    private func updateVideoConnectionOrientation() {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            
            if let videoConnection = self.videoDataOutput.connection(with: .video) {
                let videoOrientation = self.convertDeviceOrientationToVideoOrientation(self.deviceOrientation)
                if videoConnection.isVideoOrientationSupported {
                    videoConnection.videoOrientation = videoOrientation
                }
            }
        }
    }
    
    // å°†è®¾å¤‡æ–¹å‘è½¬æ¢ä¸ºè§†é¢‘æ–¹å‘
    private func convertDeviceOrientationToVideoOrientation(_ deviceOrientation: UIDeviceOrientation) -> AVCaptureVideoOrientation {
        switch deviceOrientation {
        case .portrait:
            return .portrait
        case .portraitUpsideDown:
            return .portraitUpsideDown
        case .landscapeLeft:
            return .landscapeRight
        case .landscapeRight:
            return .landscapeLeft
        default:
            return .portrait
        }
    }
    
    func switchLens(to lens: CameraLensType) {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            let position = self.isUsingFrontCamera ? AVCaptureDevice.Position.front : .back
            let deviceType: AVCaptureDevice.DeviceType
            switch lens {
            case .ultraWide:
                deviceType = .builtInUltraWideCamera
            case .wide:
                deviceType = .builtInWideAngleCamera
            case .telephoto:
                deviceType = .builtInTelephotoCamera
            }
            guard let device = AVCaptureDevice.default(deviceType, for: .video, position: position) else { return }
            do {
                let input = try AVCaptureDeviceInput(device: device)
                self.session.beginConfiguration()
                if let currentInput = self.videoDeviceInput {
                    self.session.removeInput(currentInput)
                }
                if self.session.canAddInput(input) {
                    self.session.addInput(input)
                    self.videoDeviceInput = input
                    self.videoDevice = device
                    DispatchQueue.main.async {
                        self.currentLens = lens
                    }
                }
                self.session.commitConfiguration()
            } catch {
                print("åˆ‡æ¢ç„¦æ®µå¤±è´¥: \(error)")
            }
        }
    }
    
    func isLensAvailable(_ lens: CameraLensType) -> Bool {
        let position = isUsingFrontCamera ? AVCaptureDevice.Position.front : .back
        let deviceType: AVCaptureDevice.DeviceType
        switch lens {
        case .ultraWide:
            deviceType = .builtInUltraWideCamera
        case .wide:
            deviceType = .builtInWideAngleCamera
        case .telephoto:
            deviceType = .builtInTelephotoCamera
        }
        return AVCaptureDevice.default(deviceType, for: .video, position: position) != nil
    }
}

// MARK: - Video Data Output Delegate
extension CameraService: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
        
        // èŠ‚æµå¤„ç†ï¼šé™åˆ¶å¤„ç†é¢‘ç‡åˆ°15FPS
        let currentTime = CACurrentMediaTime()
        if currentTime - lastProcessTime < processInterval {
            return
        }
        lastProcessTime = currentTime
        
        let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        
        // Apply filter if not none
        let filteredImage: CIImage
        if currentFilter != .none {
            filteredImage = FilterEngine.shared.applyFilterToCIImage(ciImage, filterType: currentFilter) ?? ciImage
        } else {
            filteredImage = ciImage
        }
        
        // Update preview on main thread
        DispatchQueue.main.async { [weak self] in
            self?.previewImage = filteredImage
        }
    }
}

// MARK: - Photo Capture Processor
class PhotoCaptureProcessor: NSObject, AVCapturePhotoCaptureDelegate {
    private let uniqueID: Int64
    private let currentFilter: FilterType
    private let completion: (Result<UIImage, Error>) -> Void
    
    init(uniqueID: Int64, currentFilter: FilterType, completion: @escaping (Result<UIImage, Error>) -> Void) {
        self.uniqueID = uniqueID
        self.currentFilter = currentFilter
        self.completion = completion
        super.init()
        print("ğŸŸ¢ PhotoCaptureProcessor åˆå§‹åŒ–å®Œæˆï¼ŒuniqueID: \(uniqueID)")
    }
    
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        print("ğŸŸ¢ photoOutput didFinishProcessingPhoto è¢«è°ƒç”¨ï¼ŒuniqueID: \(uniqueID)")
        
        if let error = error {
            print("ğŸŸ¢ æ‹ç…§é”™è¯¯: \(error)")
            completion(.failure(error))
            return
        }
        
        print("ğŸŸ¢ å¼€å§‹å¤„ç†ç…§ç‰‡æ•°æ®...")
        print("ğŸŸ¢ photo.isRawPhoto: \(photo.isRawPhoto)")
        print("ğŸŸ¢ photo.resolvedSettings: \(photo.resolvedSettings)")
        
        guard let data = photo.fileDataRepresentation() else {
            print("ğŸŸ¢ é”™è¯¯ï¼šæ— æ³•è·å–ç…§ç‰‡æ•°æ®")
            completion(.failure(CameraError.processingFailed))
            return
        }
        
        print("ğŸŸ¢ ç…§ç‰‡æ•°æ®å¤§å°: \(data.count) bytes")
        
        guard let originalImage = UIImage(data: data) else {
            print("ğŸŸ¢ é”™è¯¯ï¼šæ— æ³•ä»æ•°æ®åˆ›å»º UIImage")
            completion(.failure(CameraError.processingFailed))
            return
        }
        
        print("ğŸŸ¢ æˆåŠŸåˆ›å»º UIImageï¼Œå¤§å°: \(originalImage.size)ï¼Œæ–¹å‘: \(originalImage.imageOrientation.rawValue)")
        
        // é¦–å…ˆä¿®æ­£å›¾åƒæ–¹å‘
        let correctedImage = fixOrientation(originalImage)
        print("ğŸŸ¢ å·²ä¿®æ­£å›¾åƒæ–¹å‘: \(correctedImage.imageOrientation.rawValue)")
        
        // ç„¶ååº”ç”¨æ»¤é•œ
        let finalImage: UIImage
        if currentFilter != .none {
            print("ğŸŸ¢ åº”ç”¨æ»¤é•œ: \(currentFilter)")
            if let filteredImage = FilterEngine.shared.applyFilter(to: correctedImage, filterType: currentFilter) {
                finalImage = filteredImage
            } else {
                finalImage = correctedImage
            }
        } else {
            finalImage = correctedImage
        }
        
        print("ğŸŸ¢ å¤„ç†å®Œæˆï¼Œæœ€ç»ˆå›¾åƒå¤§å°: \(finalImage.size)")
        completion(.success(finalImage))
    }
    
    // ä¿®æ­£å›¾åƒæ–¹å‘çš„è¾…åŠ©å‡½æ•°
    private func fixOrientation(_ image: UIImage) -> UIImage {
        // å¦‚æœæ–¹å‘å·²ç»æ˜¯å‘ä¸Šçš„ï¼Œç›´æ¥è¿”å›
        if image.imageOrientation == .up {
            return image
        }
        
        // åˆ›å»ºä¸€ä¸ªCGContextå¹¶ç»˜åˆ¶ä¿®æ­£æ–¹å‘åçš„å›¾åƒ
        UIGraphicsBeginImageContextWithOptions(image.size, false, image.scale)
        image.draw(in: CGRect(origin: .zero, size: image.size))
        let normalizedImage = UIGraphicsGetImageFromCurrentImageContext()!
        UIGraphicsEndImageContext()
        
        return normalizedImage
    }
    
    func photoOutput(_ output: AVCapturePhotoOutput, willBeginCaptureFor resolvedSettings: AVCaptureResolvedPhotoSettings) {
        print("ğŸŸ¢ willBeginCaptureFor è¢«è°ƒç”¨ï¼ŒuniqueID: \(uniqueID)")
    }
    
    func photoOutput(_ output: AVCapturePhotoOutput, willCapturePhotoFor resolvedSettings: AVCaptureResolvedPhotoSettings) {
        print("ğŸŸ¢ willCapturePhotoFor è¢«è°ƒç”¨ï¼ŒuniqueID: \(uniqueID)")
    }
    
    func photoOutput(_ output: AVCapturePhotoOutput, didCapturePhotoFor resolvedSettings: AVCaptureResolvedPhotoSettings) {
        print("ğŸŸ¢ didCapturePhotoFor è¢«è°ƒç”¨ï¼ŒuniqueID: \(uniqueID)")
    }
}

// MARK: - Camera Error
enum CameraError: LocalizedError {
    case processingFailed
    
    var errorDescription: String? {
        switch self {
        case .processingFailed:
            return "Failed to process the captured photo"
        }
    }
} 
